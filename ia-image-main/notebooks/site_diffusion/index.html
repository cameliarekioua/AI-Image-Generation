<!DOCTYPE html>
<html lang="fr">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MonSite</title>
    <link rel="stylesheet" href="styles.css">
    <!-- Chargement de MathJax -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
    <h1>Diffusion</h1>

    <!-- Syst√®me d'onglets -->
    <div class="tab-container">
        <div class="tab-buttons">
            <button class="tab-button" onclick="showTab('.explications', 1)">Explication g√©n√©rale</button>
            <button class="tab-button" onclick="showTab('.calculs')">Calculs</button>
        </div>
    </div>


    <div id="explications" class="explications">
        <p>
        Les mod√®les √† diffusion sont des mod√®les qui g√©n√®rent des images en partant d'un bruit et en d√©bruitant ce dernier jusqu'√† obtenir une image plausible. Ils ont √©t√© introduis en 2015 par le papier <a href="https://arxiv.org/pdf/1503.03585" target="_blank">Deep Unsupervised Learning using Nonequilibrium Thermodynamics</a>, ont √©t√© popularis√©s par le papier <a href="https://arxiv.org/pdf/2006.11239" target="_blank">Denoising Diffusion Probabilistic Models</a> en 2020 et ont par la suite re√ßu divers am√©liorations permettant de g√©n√©rer des images de plus en plus r√©alistes et ce de plus en plus rapidement. Ils sont la technologie derri√®re de nombreux mod√®les de g√©n√©rations d'image c√©l√®bres tels que DALL-E 2, Stable Diffusion et Midjourney.
        </p>

        <!-- Pour l'image DALL-E -->
        <div class="image-container">
            <img src="assets/dall-e 2 examples.png" alt="Images g√©n√©r√©es par DALL-E 2" class="centered-image">
        </div>

        <p>
        Int√©ressons nous au formalisme math√©matique derri√®re ces mod√®les. Supposons que nous avons un jeu de donn√©es contenant N images $x_1, x_2, ..., x_N$ et que nous voulons cr√©er un mod√®le qui g√©n√®re des images semblables √† celles contenus dans ce jeu de donn√©es. Math√©matiquement, cela revient √† dire que les images de notre jeu de donn√©es sont des √©chantillons provenant d'une certaines distribution de probabilit√© $p$ et que nous voulons cr√©er un mod√®le $p_{\theta}$ qui approxime cette distribution. Et comme on sait que les r√©seaux de neurones peuvent approximer √† peu pr√®s n'importe quelle fonction, on va chercher notre mod√®le sous cette forme. <br><br>

        Lorsqu'on dit qu'un mod√®le approxime une distribution de probabilit√©, cela signifie qu'√† partir d'entr√©es quelconques, il g√©n√®re des sorties similaires √† celles de la distribution. Mais que donner comme entr√©es au mod√®le? Notre r√©seau de neurones √©tant d√©terministe, on ne peut pas donner une entr√©e fixe comme par exemple un carr√© noir car alors il g√©n√®rerait toujours la m√™me image. Il est donc n√©cessaire de lui fournir des nombres al√©atoires, et on choisit g√©n√©ralement de lui donner du bruit gaussien, c'est-√†-dire une matrice de nombres tir√©s d'une distribution normale $\mathcal{N}(0,1) : x \mapsto \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}$.
        
        <!-- Pour l'image de bruit gaussien -->
        <div class="image-container">
            <img src="assets/gaussian_noise.png" alt="Exemple de bruit gaussien" class="noise-image">
            <div class="image-caption">Exemple de bruit gaussien</div>
        </div>
        </p>

        <p>
        La t√¢che de notre mod√®le est donc la suivante : produire une image plausible √† partir d'un bruit gaussien. Une approche na√Øve serait de donner en entr√©e un bruit au r√©seau de neurones, de comparer sa sortie √† une image de notre jeu de donn√©es et de l'entra√Æner ainsi par descente de gradient. Cependant empiriquement cela ne fonctionne pas car l'entra√Ænement n'est pas assez guid√©. Le r√©seau g√©n√®re initialement du bruit et en comparant ce bruit √† une image avant de changer d'image √† la prochaine it√©ration, on ne lui fournit pas un signal d'erreur suffisament clair pour apprendre. Pour simplifier la t√¢che du mod√®le, on peut changer le protocole d'entra√Ænement : on lui donne une image bruit√©e et on lui demande de produire une version l√©g√®rement moins bruit√©e de cette image. Si le mod√®le apprend √† r√©aliser cette t√¢che pour tout niveau de bruit on pourra partir d'un bruit gaussien et lui demander de le d√©bruiter petit √† petit jusqu'√† obtenir une image plausible.
        </p> <br>

        <p>
        Cette fa√ßon de pr√©senter les mod√®les √† diffusion est assez commune et permet de comprendre de mani√®re intuitive le fonctionnement de ces mod√®les mais elle n'explique pas un certain nombre de propri√©t√©s de ces derniers. Par exemple pourquoi est ce que des bruits diff√©rents conduisent √† des images diff√©rentes, comment le mod√®le choisit-il d'associer un bruit √† une image de chat et un autre bruit √† un visage? Pour r√©pondre √† ces questions, il est int√©ressant de s'int√©resser √† l'espace dans lequel vivent les images.
        </p> <br>

        <h2>L'espace des images</h2>

        <p>
        Int√©ressons nous au cas d'un jeu d'images rgb de taille 128x128 pixels. Si les valeurs des pixels sont comprises entre 0 et 1 on peut voir l'espace des images possibles comme un hypercube de c√¥t√© 1 et de dimension 128x128x3. Le processus de diffusion peut alors √™tre r√©interpr√©t√© comme un d√©placement dans cet hypercube. Les images de notre jeu de donn√©es sont des zones de haute densit√© de probabilit√© de l'hypercube et le r√¥le de notre mod√®le est de partir d'un bruit gaussien (un point dans l'hypercube) et de le d√©placer vers un point d'une zone de forte densit√© de probabilit√© et donc susceptible de contenir une image provenant de notre jeu de donn√©es.
        </p>

        <!-- Pour l'illustration de l'espace des images -->
        <div class="image-container">
            <img src="assets/image_space.png" alt="Espace des images" class="centered-image">
            <div class="image-caption">Repr√©sentation sch√©matique de l'espace des images.</div>
        </div>

        <p>
        Le mod√®le va donc apprendre un champ de vecteurs, il associe √† chaque point de l'espace un direction dans laquelle bouger le point pour se rapprocher d'une vraie image. Cela explique alors pourquoi des bruits diff√©rents conduisent √† des images diff√©rentes. Si le mod√®le d√©cide de g√©n√©rer une image de panda c'est parce que le bruit initial se trouve dans un point du champ de vecteur qui pointe vers une portion de l'espace contenant des images de panda.
        </p> <br>

        <p>
        Pour entra√Æner le mod√®le on doit lui fournir des images √† diff√©rents niveaux de bruits en s'assurant qu'on couvre bien l'ensemble de l'espace entre les images de notre distribution et le bruit gaussien. Il faut donc ajouter du bruit √† l'image initiale jusqu'√† ce que cette derni√®re ne contienne plus aucune information. On nomme ce processus le "noising process".

        <!-- Pour l'illustration du noising process -->
        <div class="image-container">
            <img src="assets/noising_process.png" alt="Illustration du noising process" class="noising-image">
            <div class="image-caption">Illustration du noising process : une image est progressivement bruit√©e jusqu'√† ne plus contenir d'information.</div>
        </div>

        Le processus inverse qui prend une image bruit√©e et renvoie une image l√©g√®rement moins bruit√©e se nomme quand √† lui le "denoising process".
        </p> <br>

        <p>
        Il existe de nombreuses fa√ßons de d√©finir le noising et le denoising process. Diff√©rentes formulations permettent d'am√©liorer la qualit√© des images ou de r√©duire le nombre d'√©tapes de d√©bruitage. Le papier DDPM de 2020 utilise par exemple le noising process $x_{t+1} = \sqrt{1 - \beta_t} \cdot x_t + \sqrt{\beta_t} \cdot \epsilon_t$ o√π $\epsilon_t$ est un bruit gaussien et $\beta_t$ est un hyperparam√®tre, ce qui (apr√®s bien des calculs) conduit au denoising process $x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \cdot (x_t - \frac{\beta_t}{\sqrt{1 - \overline{\alpha}_t}} \cdot \epsilon_{\theta}(x_t, t))$. <br><br>

        Cependant, des formulations plus simples sont possibles et parfois toutes aussi performantes, comme le montre le papier <a href="https://arxiv.org/pdf/2305.03486" target="_blank">Iterative ùõº-(de)Blending: a Minimalist Deterministic Diffusion Model</a> qui utilise tout simplement une interpolation lin√©aire entre l'image et le bruit pour le noising process $ x_t = (1-t) \cdot x_0 + t \cdot x_1 $ avec t tir√© uniform√©ment entre 0 et 1 et $ x_{t-1} = x_t + \frac{1}{T} \cdot D_{\theta}(x_t, t) $ o√π $ D_{\theta}(x_t, t) $ est la sortie du r√©seau de neurones auquel on a appris √† pr√©dire $x_1 - x_0$ (on note qu'il s'agit d'un vecteur dans l'espace des images pointant vers une image du jeu de donn√©es x0 √† partir du bruit gaussien $x_1$).
        </p>

    </div>

    <div id="calculs" class="calculs invisible">
        On d√©finit le processus de bruitage comme une cha√Æne de markov allant de $x_0$ √† $x_T$ o√π $x_0$ est l'image d'origine et $x_T$ est le bruit gaussien.
        <div class="image-container">
            <img src="assets/The-forward-and-backward-processes-of-the-diffusion-model-The-credit-of-the-used-images.png" alt="forward and backward process" class="centered-image">
        </div>
        On note $q(x_t | x_{t-1})$ la probabilit√© de passer de l'image $x_{t-1}$ √† l'image $x_t$. On note aussi $\alpha_t = 1 - \beta_t$ et $\overline{\alpha}_t = \prod_{s=1}^t \alpha_s$. <br>
        On peut montrer que la probabilit√© de passer de $x_0$ √† $x_t$ est donn√©e par la formule suivante :
        $ q(x_t | x_0) = \sqrt{\overline{\alpha}_t} x_0 + \sqrt{1 - \overline{\alpha}_t} \epsilon $ o√π $ \epsilon $ ~ $ N(0, I) $. <br>
        Autrement dit, on a une formule explicite qui nous permet de passer de $x_0$ √† n'importe quel niveau de bruit $x_t$ du processus de bruitage. <br><br>

        On note d√©sormais $p(x_{t-1} | x_t)$ la probabilit√© de passer de l'image $x_t$ √† l'image $x_{t-1}$.<br>
        On param√©trise cette probabilit√© par un r√©seau de neurones $p_{\theta}(x_{t-1} | x_t)$ de param√®tres $ \theta $ et par sym√©trie avec le forward process on la cherche √©galement sous la forme d'une gaussienne $p(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_{\theta}(x_t, t), \Sigma_{\theta}(x_t, t))$. <br>
        L'objectif est donc de trouver les param√®tres $ \theta $ tels que les zones de l'espace correspondant au jeu de donn√©es soient des zones de haute densit√© de probabilit√© pour la mod√®le, c'est-√†-dire qu'on veut maximiser la probabilit√© $ p_{\theta}(x_0) $. <br><br>

        On minise donc classiquement : $L = E[-log(p_{\theta}(x_0))]$. <br>

        Apr√®s calculs, on trouve que $L$ est √©quivalent √† : $L = E[\frac{1}{2} ||\epsilon - \epsilon_{\theta}(x_t, t)||^2]$ o√π $\epsilon_{\theta}(x_t, t)$ est la sortie du r√©seau de neurones. <br>

        Autrement dit, on cherche √† minimiser la distance entre le bruit que l'on a ajout√© √† l'image et le bruit que le mod√®le pr√©dit. <br>
        <div class="image-container">
            <img src="assets/training_algo.png" alt="training algorithm" class="centered-image">
        </div>

        Et on peut √©galement montrer que $p_{\theta}(x_{t-1} | x_t)$ est une gaussienne de moyenne $ \mu_{\theta}(x_t, t) = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{\beta_t}{\sqrt{1 - \overline{\alpha}_t}} \epsilon_{\theta}(x_t, t)) $ et de variance $ \Sigma_{\theta}(x_t, t) = \sigma^2_{\theta}(x_t, t) I $ o√π $\sigma^2_{\theta}(x_t, t) = \frac{1 - \overline{\alpha}_{t-1}}{1 - \overline{\alpha}_t}$, ce qui permet de progressivement reconstruire $ x_0 $ √† partir d'un bruit gaussien $ x_T $. <br>
        <div class="image-container">
            <img src="assets/sampling_algo.png" alt="sampling algorithm" class="centered-image">
        </div>
        
    </div>


    <script>
        function showTab(classe) {
            if (classe == ".explications"){
                autre_classe = ".calculs";
            } else {
                autre_classe = ".explications";
            }
            var contents1 = document.querySelectorAll(classe);
            contents1.forEach(function(content) {
                if (content.classList.contains('invisible')) {
                    content.classList.remove('invisible');
                }
            });
            var contents2 = document.querySelectorAll(autre_classe);
            contents2.forEach(function(content) {
                if (!content.classList.contains('invisible')) {
                    content.classList.add('invisible');
                }
            });

            // Rafra√Æchir MathJax
            if (window.MathJax) {
                MathJax.typeset();
            }
        }
    </script>

</body>
</html>
