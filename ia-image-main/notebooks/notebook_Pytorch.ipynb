{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction à Pytorch","metadata":{}},{"cell_type":"markdown","source":"## Installation et Import","metadata":{}},{"cell_type":"code","source":"# Si PyTorch n'est pas installé, décommente la ligne suivante :\n# !pip install torch torchvision\n\nimport torch\n\nprint('PyTorch version:', torch.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T12:25:28.514653Z","iopub.execute_input":"2025-04-08T12:25:28.515034Z","iopub.status.idle":"2025-04-08T12:25:32.670452Z","shell.execute_reply.started":"2025-04-08T12:25:28.515003Z","shell.execute_reply":"2025-04-08T12:25:32.669372Z"}},"outputs":[{"name":"stdout","text":"PyTorch version: 2.5.1+cu121\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## 1.Les Tenseurs\n\nPyTorch définit une classe appelée Tensor (torch. Tensor) pour stocker les données et opérer sur des tableaux rectangulaires multidimensionnels homogènes de nombres. Ils sont similaires aux tableaux NumPy, mais permettent entre autres l'exécution sur GPU et le calcul automatique des gradients.","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Création de Tenseurs","metadata":{}},{"cell_type":"code","source":"# Création d'un tenseur à partir d'une liste\na = torch.tensor([1.0, 2.0, 3.0])\nprint('Tenseur a:', a)\nprint('Dimensions de a:', a.shape)\nprint('Type de données de a:', a.dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T12:25:32.671573Z","iopub.execute_input":"2025-04-08T12:25:32.672005Z","iopub.status.idle":"2025-04-08T12:25:32.779118Z","shell.execute_reply.started":"2025-04-08T12:25:32.671963Z","shell.execute_reply":"2025-04-08T12:25:32.777685Z"}},"outputs":[{"name":"stdout","text":"Tenseur a: tensor([1., 2., 3.])\nDimensions de a: torch.Size([3])\nType de données de a: torch.float32\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.2  Exemples","metadata":{}},{"cell_type":"code","source":"# Tenseur rempli de zéros\nz = torch.zeros((2, 3))\nprint('Tenseur de zéros:', z)\n\n# Tenseur aléatoire\nr = torch.rand((2, 2))\nprint('Tenseur aléatoire:', r)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T12:25:32.781720Z","iopub.execute_input":"2025-04-08T12:25:32.782141Z","iopub.status.idle":"2025-04-08T12:25:32.797010Z","shell.execute_reply.started":"2025-04-08T12:25:32.782107Z","shell.execute_reply":"2025-04-08T12:25:32.795807Z"}},"outputs":[{"name":"stdout","text":"Tenseur de zéros: tensor([[0., 0., 0.],\n        [0., 0., 0.]])\nTenseur aléatoire: tensor([[0.0014, 0.1866],\n        [0.5420, 0.3643]])\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 2. Opérations sur les tenseurs ","metadata":{}},{"cell_type":"code","source":"a = torch.tensor([1.0, 2.0])\nb = torch.tensor([3.0, 4.0])\n\n# Addition\naddition = a + b\nprint('Addition:', addition)\n\n# Multiplication élément par élément\nmult_elem = a * b\nprint('Multiplication élément par élément:', mult_elem)\n\n# Produit scalaire\ndot_product = torch.dot(a, b)\nprint('Produit scalaire:', dot_product)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T12:25:32.798440Z","iopub.execute_input":"2025-04-08T12:25:32.798739Z","iopub.status.idle":"2025-04-08T12:25:32.817734Z","shell.execute_reply.started":"2025-04-08T12:25:32.798711Z","shell.execute_reply":"2025-04-08T12:25:32.816564Z"}},"outputs":[{"name":"stdout","text":"Addition: tensor([4., 6.])\nMultiplication élément par élément: tensor([3., 8.])\nProduit scalaire: tensor(11.)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# 4. Autograd\n\nLe module autograd offre un moyen simple de calculer automatiquement les gradients, utilisés pour optimiser les paramètres du modèle via la descente de gradient, pour toute fonction opérée au sein des réseaux neuronaux. L'ajout d'un tenseur avec requires_grad=True indique à autograd que chaque opération sur ce tenseur doit être suivie, ce qui permet une différenciation automatique.","metadata":{}},{"cell_type":"code","source":"# Création d'un tenseur pour lequel on souhaite calculer le gradient\nx = torch.tensor([2.0], requires_grad=True)\n\n# Définition d'une fonction : y = x^2 + 3x + 1\ny = x**2 + 3*x + 1\n\n# Calcul du gradient dy/dx\ny.backward()\n\nprint('Gradient de y par rapport à x:', x.grad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T12:25:32.818926Z","iopub.execute_input":"2025-04-08T12:25:32.819277Z","iopub.status.idle":"2025-04-08T12:25:32.857152Z","shell.execute_reply.started":"2025-04-08T12:25:32.819236Z","shell.execute_reply":"2025-04-08T12:25:32.856051Z"}},"outputs":[{"name":"stdout","text":"Gradient de y par rapport à x: tensor([7.])\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# 5. Régression linaire\nNous allons créer un modèle de régression linéaire qui apprend la relation suivante : y = 2x.","metadata":{}},{"cell_type":"code","source":"# Données d'entrée et sortie\nx = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\ny = torch.tensor([[2.0], [4.0], [6.0], [8.0]])\n\n# Initialisation des paramètres (poids et biais) avec gradient activé\nw = torch.tensor([[0.0]], requires_grad=True)\nb = torch.tensor([[0.0]], requires_grad=True)\n\n# Taux d'apprentissage\nlr = 0.01\n\n# Boucle d'entraînement\nfor epoch in range(100):\n    # Prédiction : calcul de la sortie du modèle\n    y_pred = x @ w + b\n\n    # Calcul de l'erreur (Mean Squared Error)\n    loss = ((y_pred - y) ** 2).mean()\n\n    # Calcul des gradients via backpropagation\n    loss.backward()\n\n    # Mise à jour des paramètres sans traçabilité (désactivation temporaire du calcul automatique)\n    with torch.no_grad():\n        w -= lr * w.grad\n        b -= lr * b.grad\n\n        # Remise à zéro des gradients afin qu'ils ne s'accumulent pas\n        w.grad.zero_()\n        b.grad.zero_()\n\n    # Affichage périodique de la perte\n    if epoch % 10 == 0:\n        print(f'Epoch {epoch}: Loss = {loss.item()}')\n\nprint(f'Paramètres finaux: w = {w.item()}, b = {b.item()}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T12:25:32.858407Z","iopub.execute_input":"2025-04-08T12:25:32.858715Z","iopub.status.idle":"2025-04-08T12:25:32.920616Z","shell.execute_reply.started":"2025-04-08T12:25:32.858689Z","shell.execute_reply":"2025-04-08T12:25:32.919630Z"}},"outputs":[{"name":"stdout","text":"Epoch 0: Loss = 30.0\nEpoch 10: Loss = 0.8330377340316772\nEpoch 20: Loss = 0.07510896027088165\nEpoch 30: Loss = 0.052382320165634155\nEpoch 40: Loss = 0.048858530819416046\nEpoch 50: Loss = 0.04600245878100395\nEpoch 60: Loss = 0.04332456737756729\nEpoch 70: Loss = 0.04080278053879738\nEpoch 80: Loss = 0.03842790424823761\nEpoch 90: Loss = 0.0361911877989769\nParamètres finaux: w = 1.846347451210022, b = 0.45175737142562866\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Nous allons initialiser les paramètres (poids et biais) et utiliser la descente de gradient pour ajuster ces paramètres.Le résultat final devrait s'approcher d'une valeur de w égale à 2 et d'un b proche de 0.\n","metadata":{}},{"cell_type":"markdown","source":"# 6. Utilisation de PyTorch pour la Génération d'Images\n\nPyTorch est particulièrement populaire pour entraîner des modèles de génération d’images. Par exemple, grâce à autograd, le calcul des gradients est automatique, simplifiant ainsi l'entraînement des réseaux de neurones. De plus, PyTorch permet d'exécuter des calculs sur GPU, accélérant considérablement l'entraînement, ce qui est particulièrement utile pour les grands modèles de génération d'images.\n\n## 6.1 Exemple simplifié","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\n\n# Exemple d'un générateur simplifié\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(100, 256),\n            nn.ReLU(True),\n            nn.Linear(256, 512),\n            nn.ReLU(True),\n            nn.Linear(512, 784),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        img = self.model(z)\n        img = img.view(z.size(0), 1, 28, 28)  # Reshape pour obtenir une image 28x28 (exemple MNIST)\n        return img\n\n# Création du générateur\nnetG = Generator()\n\n# Optimiseur\noptimizerG = optim.Adam(netG.parameters(), lr=0.0002)\n\n# Exemple d'entraînement pour un batch fictif\nbatch_size = 64\nnoise = torch.randn(batch_size, 100)  # Bruit aléatoire\nfake_images = netG(noise)\n\n# Affichage de la forme du batch d'images générées\nprint('Shape des images générées:', fake_images.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T12:25:32.921457Z","iopub.execute_input":"2025-04-08T12:25:32.921715Z","iopub.status.idle":"2025-04-08T12:25:35.699051Z","shell.execute_reply.started":"2025-04-08T12:25:32.921693Z","shell.execute_reply":"2025-04-08T12:25:35.697911Z"}},"outputs":[{"name":"stdout","text":"Shape des images générées: torch.Size([64, 1, 28, 28])\n","output_type":"stream"}],"execution_count":7}]}